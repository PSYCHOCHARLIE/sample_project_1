{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ba6d4c-daff-424d-8c55-7a6f2f25c848",
   "metadata": {},
   "source": [
    "# Never test your model on data that it has learned from"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0beec11-677e-4415-8c70-536ea0f8a522",
   "metadata": {},
   "source": [
    "Tidbit:\n",
    "    1. If u have structured data, use ensemble methods\n",
    "    2. If u have unstructured data, use deep learning or transfer learning  \n",
    "\n",
    "    THESE ARE ALL STRUCTURED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be156576-e4ab-4244-8ce7-f68a3b7aae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "heart_disease = pd.read_csv(\"heart-disease.csv\")\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7adf36-81ad-408e-8caf-9b877aff0b02",
   "metadata": {},
   "source": [
    "SUPERVISED LEARNING IN WHICH INPUT AND OUTPUT DATA IS PROVIDED AND THEN THE MODEL IS TRAINED ON THAT TO MAKE PREDICTIONS. EG: FAKE MAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b1459c-5c4f-4cbf-b99e-b48a305da732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X (feature matrix)\n",
    "X = heart_disease.drop(\"target\", axis = 1)  # axis = 1 => column\n",
    "\n",
    "# Create Y (labels)\n",
    "Y = heart_disease[\"target\"]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ce564-9fdb-40eb-b516-8f6ddd854c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features are the input variables or attributes that the machine learning model uses to make predictions.\n",
    "# Each row in the dataset corresponds to an observation or data point, and the columns represent different features.\n",
    "# Features are the characteristics or properties of the data that the model analyzes to learn patterns.\n",
    "# For example, in a dataset of houses, the features might include square footage, number of bedrooms, and neighborhood.\n",
    "\n",
    "X   # Feature   ----> Data on which the model will train\n",
    "Y   # Label     ----> Result\n",
    "\n",
    "# Labels, also known as the target variable or output variable, are the values that the machine learning model is trying to predict.\n",
    "# The goal of the model is to learn a mapping from the features to the labels.\n",
    "# In a supervised learning scenario, the dataset is typically labeled, meaning that it includes both the features and the corresponding correct labels.\n",
    "# Using the house example, the label might be the price of the house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cefb3a7-7614-4f7b-8e76-3499b0f734d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.  Choose the right model and hyperparameters\n",
    "from sklearn.ensemble import RandomForestClassifier   # RandomForest  ---->   Reduce Overfitting\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Hyperparameters are external configuration settings that influence the learning process but are not learned from the data.\n",
    "\n",
    "# We'll keep the default hyperparameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e9e6309-0127-48a0-8179-92b311db9bff",
   "metadata": {},
   "source": [
    "Categorical Prediction:\n",
    "# CLASSIFIER - YOU HAVE TO CHOOSE THAT IN WHICH CATEGORY IT BELONGS TO   (LIKE IT BELONGS TO    0  OR   1 )\n",
    "-> Assigns an observation to a specific category.\n",
    "-> Output is a label representing a group.\n",
    "-> Example: Classifying emails as spam or not spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b4f48-664f-49e3-a571-b8829d407db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to the training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "\n",
    "# test_size=0.2 means that 20% of the data will be used for testing, and 80% for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4c22cc-dcd7-4fa7-8151-c40c7cac945a",
   "metadata": {},
   "source": [
    " X_train: This subset of the features is used for training the machine learning model.\n",
    " Y_train: The corresponding subset of labels/targets for the training set. Each row in X_train has a corresponding label in Y_train.\n",
    "\n",
    " X_test: This subset of the features is reserved for testing the trained model.\n",
    " Y_test: The corresponding subset of labels/targets for the testing set. Each row in X_test has a corresponding label in Y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65b0bb-0d9c-47a4-be16-66a7bec8d90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the patterns in the traininig data\n",
    "clf.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1116ddcd-27c7-4283-8117-d46b71f0411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e1839-a164-45c0-a93f-e6ad7a96c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now , testing the model on X_test  OR  the MODEL will make predictions on the new data\n",
    "# It will predicts the value of Y_test which is stored in the variable Y_preds on the basis of X_test\n",
    "\n",
    "Y_preds = clf.predict(X_test)\n",
    "Y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e39f0fe-3170-40b8-a131-df22615a1084",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c339c6-4227-46f0-9c62-3bf0d477ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluatae the model on the training data and test data\n",
    "\n",
    "clf.score(X_train, Y_train)     # 1 is the max value of score      RANGE  ==>  [0,1]\n",
    "\n",
    "# score is a method of the RandomForestClassifier class that calculates the accuracy of the model on a given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0395a20c-744e-4bf6-bb5f-77d813bf93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test between the original data sets\n",
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfba847-3881-431a-b7fc-82bf732fa1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(Y_test, Y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e5dd88-7e96-43a7-acbc-70162661f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, Y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb81a0-d5a9-4662-bd58-d7f7f98c4c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test between the predicted datasets\n",
    "accuracy_score(Y_test, Y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3576e421-ae04-4bcd-9440-2ced2873159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. improve the model\n",
    "# Try different amount of n_estimators\n",
    "np.random.seed(42)\n",
    "\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(X_train, Y_train)\n",
    "    print(f\"Model accuracy on test set:{clf.score(X_test, Y_test) * 100:.2f}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd1953-3abc-4c12-a290-65a735e839f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Save a model and load it\n",
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open(\"random_forst_model_1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bfedf7-f20a-4807-968f-121d4c4549d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"random_forst_model_1.pkl\", \"rb\"))\n",
    "loaded_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5e477e4-cf2b-4e19-ac64-b1ed7e66bc57",
   "metadata": {},
   "source": [
    "## Getting our data ready to be used with machine learning\n",
    "\n",
    "Three main things we have to do:\n",
    "    1. Split the data into features and labels (usually `X` & `Y`)\n",
    "    2. Filling (also called imputing) or disregarding missing values\n",
    "    3. Converting non-numerical values to numerical values (also called feature encoding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b446d069-1b48-4ff6-8bc9-70b3d4fc3700",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_disease.drop(\"target\", axis = 1)  # feature\n",
    "y = heart_disease[\"target\"]                 # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d49e2-2188-4e5f-a259-86a3d62ae51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115b403b-a3ea-4dac-b08c-962d6f472130",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff53e3-c587-452c-8e53-116c1db50d3a",
   "metadata": {},
   "source": [
    "## Make sure the values are all numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd023b82-6cc8-4b09-93dd-8cc251d4d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales = pd.read_csv(\"car-sales-extended.csv\")\n",
    "len(car_sales), car_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945bac30-f7d9-4b83-8c04-83af02feac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dda1e6-0de3-40a9-8e6c-b46a310e8b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X/y\n",
    "X = car_sales.drop(\"Price\", axis = 1)\n",
    "y = car_sales[\"Price\"]\n",
    "\n",
    "# Split into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a065911b-c28c-4d5c-b400-03d7fdf135cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder # convert categorical variables into a numerical format\n",
    "from sklearn.compose import ColumnTransformer #  used to apply transformations selectively to different columns\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]        # Doors is c_f coz each door types has specific values\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder = \"passthrough\") # remainder=\"passthrough\"' argument indicates that all other columns should be left unchanged\n",
    "# \"one_hot\": This is a string label or name that you can use to refer to this specific transformation later in your code.\n",
    "# one_hot: This is the actual instance of the OneHotEncoder class that you created earlier. This is the transformer that will be applied to the specified columns.\n",
    "transformed_X = transformer.fit_transform(X) # transformed_X will work on the dataframe to change it into numbers\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166f6471-2b7b-45c7-b050-040cd0971f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transformed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e8c08-4a73-4e13-ae87-4ee8844c3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the data\n",
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]]) # [[]] When you want to select multiple columns from a DataFrame \n",
    "dummies.head()\n",
    "# dummies  contains the original columns (\"Make\", \"Colour\", \"Doors\") replaced with their one-hot encoded representations."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0289b03-ebaf-47c9-921c-78f58cb0b6da",
   "metadata": {},
   "source": [
    "Continuous Prediction:\n",
    "# REGRESSOR -> COMPLEX MODEL THAN CLASSIFIER,  IT HAS NOT TO CHOOSE BETWEEN THE CLASSES BUT TO PREDICT IN NUMBERS \n",
    "\n",
    "-> Predicts a value on a continuous scale.\n",
    "-> Output is a numerical value.\n",
    "-> Example: Predicting house prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9528b2b-0c39-4960-af94-bbcce37c26a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's refit the model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "np.random.seed(42) #used to give the same result again and again , coz one don't train the model on the same data again and again\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a31a6d0-b0cb-414b-a343-be96a05fb59c",
   "metadata": {},
   "source": [
    "## What if there is missing values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7471aaed-a72b-4f99-af48-6496c041b54e",
   "metadata": {},
   "source": [
    "1. Fill them with some values (also known as imputation)\n",
    "2. Remove the samples with the missing data altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138b807-008e-497e-bc52-114f2f050737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import car sales missing data\n",
    "car_sales_missing = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.isna().sum() # effectively counting the number of True values along each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d38883-5c0c-4726-b599-39a26a2008f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing datas with pandas\n",
    "\n",
    "car_sales_missing[\"Make\"].fillna(\"Missing\", inplace= True)\n",
    "car_sales_missing[\"Colour\"].fillna(\"Missing\", inplace= True)\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(), inplace= True)\n",
    "car_sales_missing[\"Doors\"].fillna(4, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a1e06-3681-438e-ad8a-2e89f5644162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dataframe again\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8821e07-ec98-4fc6-af2b-c2eaebf29835",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e69922-9299-41e5-ba53-6c72c2f7a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows with missing price values\n",
    "car_sales_missing.dropna(axis=0, inplace = True)\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431d8400-ea6e-4dd1-af68-ad419b86a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "X = car_sales_missing.drop(\"Price\", axis = 1)  # ALREADY DROP KR DIA HAI UPAR\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e818981-d4d2-44e6-93f4-75ae4a6fde18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT THE DATA TO NUMBERS\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]        # Doors is c_f coz each door types has specific values\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder = \"passthrough\")\n",
    "# \"one_hot\": This is a string label or name that you can use to refer to this specific transformation later in your code.\n",
    "# one_hot: This is the actual instance of the OneHotEncoder class that you created earlier. This is the transformer that will be applied to the specified columns.\n",
    "transformed_X = transformer.fit_transform(car_sales_missing) \n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f5baec-be04-4612-8733-9cf440b054aa",
   "metadata": {},
   "source": [
    "# OPTION 2. FILL MISSING VALUES WITH SKL NOT WITH PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04807e37-d879-4372-9e69-badee3141286",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing = pd.read_csv(\"car-sales-extended-missing-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c7c57-662d-4fe6-912f-a70e22a9d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f770f29-a529-41ba-8496-0c0680f14964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Price label with no values in it\n",
    "car_sales_missing.dropna(subset=[\"Price\"], inplace = True)\n",
    "car_sales_missing.isna().sum()  # Other columns values get changed coz some missing values were overlapping with the Price missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90e77b8-89b0-4abe-a264-846f4a91a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and y\n",
    "X = car_sales_missing.drop(\"Price\", axis = 1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc58580-fa0b-4830-aa3c-b09313180196",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89768a5e-14d9-498a-9471-f525229c40ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Missing values (IMPUTATION) in scilearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Fill missing values with 'missing' & numerical values with 'mean'    of  COLUMNS\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")   \n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "# If \"constant\", then replace missing values with fill_value.\n",
    "# fill_value : str or numerical value, default=None\n",
    "\n",
    "\n",
    "# Define Columns\n",
    "cat_features = [\"Make\", \"Colour\"]\n",
    "door_features = [\"Doors\"]\n",
    "num_features = [\"Odometer (KM)\"]\n",
    "\n",
    "\n",
    "# Create an imputer  (SOMETHING THAT FILLS MISSING DATA)  described above\n",
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer, cat_features),       # \"cat_imputer\" is just a name which  can be accessed later but not here\n",
    "    (\"door_imputer\", door_imputer, door_features),\n",
    "    (\"num_imputer\", num_imputer, num_features)\n",
    "])\n",
    "\n",
    "\n",
    "# Transform the data\n",
    "filled_X = imputer.fit_transform(X)\n",
    "filled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4685914a-8f1c-481d-bcea-899057b4b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled = pd.DataFrame(filled_X, columns = [\"Make\", \"Colour\",\"Doors\", \"Odometer (KM)\"])\n",
    "car_sales_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6339f980-5947-4546-b77c-0420c53f643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a3d2c6-136a-493e-be2d-653ba59b0ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]        # Doors is c_f coz each door types has specific values\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder = \"passthrough\")\n",
    "# \"one_hot\": This is a string label or name that you can use to refer to this specific transformation later in your code.\n",
    "# one_hot: This is the actual instance of the OneHotEncoder class that you created earlier. This is the transformer that will be applied to the specified columns.\n",
    "transformed_X = transformer.fit_transform(car_sales_filled) # transformed_X will work on the dataframe to change it into numbers\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade07ee8-26be-4cfc-929a-12897d550d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we've got our data in nos and filled the missing values\n",
    "# Let's fit the model\n",
    "\n",
    "np.random.seed(42)  # CHANGING SEED VALUES AFFECT THE MODEL\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1c1adf-fa12-4484-a79e-74bbbb80a69e",
   "metadata": {},
   "source": [
    "## CHOOSING THE RIGHT ESTIMATOR / ALGORITHM\n",
    "\n",
    "If you're working on a model and looking to use sklearn and not sure what model you should use then,,,,,\n",
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html#choosing-the-right-estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b70b3f6-94d1-43eb-99fe-f310f65c72ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Picking a ml model for a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb8e751-273d-4e0a-9b66-0aefb45c1349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get California Housing dataset   (already in sklearn just need to import)\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52d1a314-d9d3-413a-a4c8-f3567c61b255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.23  \n",
       "1        -122.22  \n",
       "2        -122.24  \n",
       "3        -122.25  \n",
       "4        -122.25  \n",
       "...          ...  \n",
       "20635    -121.09  \n",
       "20636    -121.21  \n",
       "20637    -121.22  \n",
       "20638    -121.32  \n",
       "20639    -121.24  \n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.DataFrame(housing[\"data\"], columns=housing[\"feature_names\"])\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d0ba18-bfb7-453f-8120-141aece9156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[\"target\"] = housing[\"target\"]\n",
    "# housing_df = housing_df.drop(\"MedHouseVal\", axis = 1)\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5aad6b-a671-4349-843f-e3e6e2b46f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import algorithm/estimator\n",
    "from sklearn.ensemble import RandomForestRegressor  # is better coz uses decision trees\n",
    "# from sklearn.linear_model import Ridge            # thik hai\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis = 1)\n",
    "y = housing_df[\"target\"] # median house price id $ 100,000s\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate and fit the model (in the trainig data)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# check the score of the model \n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db53b8f3-bf98-49c1-9a5f-f27d34f22c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease = pd.read_csv(\"heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda1c9a4-a097-4985-a0ed-7bc34c2e374b",
   "metadata": {},
   "source": [
    "### Consulting the map and it says try `LinearSVC` # (used for both classification and regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8403fd-68ef-4634-ab0f-d87e947b85a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LinearSVC estimator class\n",
    "from sklearn.svm import LinearSVC                        \n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heart_disease.drop(\"target\", axis = 1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate linearSVC\n",
    "model = LinearSVC(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model \n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb5e74-205f-4fb7-9220-7a0736f24f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c24aac0-2449-4ad4-8443-f1e44e8edfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heart_disease.drop(\"target\", axis = 1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model \n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bf303b-f5ee-44ab-9f46-7cd63af971f1",
   "metadata": {},
   "source": [
    "# Make predictions using a ML model\n",
    "\n",
    "2 ways to make predictions:\n",
    "\n",
    "    1.predict()\n",
    "    2.predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2924e64-3c80-4b03-8318-1f9565c0a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c685d592-67e4-411b-a807-c87bfea9e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d478455a-e669-4f9a-92e1-7d805d0230ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afacc7db-fc74-4468-b450-6678b13a8bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions to truth table to evaluate model\n",
    "y_preds = model.predict(X_test)    #  X_test dia hai to y_preds me y_test ki value hai\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59acd27-61a1-473d-b4a5-21aa09fe55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b0ebf-3ff9-4daf-9089-a5146c68e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One more way\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb8322-4593-4db3-842f-f19d71af091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba() returns probabilities of a classification label\n",
    "model.predict_proba(X_test[:5])\n",
    "# It returns the probabilities whether it's a 1 or 0 \n",
    "# col 1 represent 0 and col 2 rep 1\n",
    "# 0.89 means first is 0 check below it is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b9032d-ab04-49a6-9e2a-a8eec456db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict on the same data\n",
    "model.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6e5ca5-1e77-4cb9-bff0-8317144b0fc6",
   "metadata": {},
   "source": [
    "`predict()` can also be used for regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff0b4c-9176-4965-a142-7e09132fd678",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa4dcaf-c0de-4477-83f9-e6783023d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "X =  housing_df.drop(\"target\", axis =1)\n",
    "y =  housing_df[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_preds = model.predict(X_test)  #  X_test dia hai to y_preds me y_test ki value hai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851d37d9-bebb-4b44-81f4-5971e5f01ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee4153-af53-4f20-b2ee-3385cc75dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a834f-edb7-42da-9e82-fc3610923489",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_preds), len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25fe433-399c-4601-b237-445ff300b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0f5e72-5e1d-4a00-9a5d-4a49e7cb1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the predictions to the truth\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b119b416-cdd0-41db-8803-e96f8135101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[\"target\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f420a431-32fd-4f2f-987d-3333d3bc9199",
   "metadata": {},
   "source": [
    "##Evaluating a machine learning model\n",
    "\n",
    "Three ways to evaluate Scikit-Learn models/estimators:\n",
    "    1. Estimators a built in score() method\n",
    "    2. The `scoring` parameter\n",
    "    3. Problem-specific metric functions     https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ccd550-039c-4812-b345-3a08345f2da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heart_disease.drop(\"target\", axis = 1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=50)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eddc0f6-4794-4476-9af6-d150d770871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bfb939-d920-4b42-8b4c-16542f82163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00341ee5-9811-4ed3-8b71-3b667a1817ac",
   "metadata": {},
   "source": [
    "# Evaluating a model using scoring parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451eab9-1676-4f86-9aa1-a8a5c0998b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis = 1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16775eab-106b-4e41-a335-1e5a8bbef70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fded9e-bcd7-415b-96ab-9001b0db73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(model, X, y, cv=5)    #  Cross validation  5 = default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4917c1ef-95cc-444e-982e-6e96ed51f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(model, X, y, cv=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39f89c-b6ea-4c3c-9dff-8fbdc9c05fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Single training and test split score\n",
    "model_single_score = model.score(X_test, y_test)\n",
    "\n",
    "# Take the mean of 5-fold-cross-validation score\n",
    "model_cross_val_score = np.mean(cross_val_score(model, X, y, cv = 5))\n",
    "\n",
    "# Compare the data\n",
    "model_single_score,  model_cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c90a95-af81-401f-bf9a-53b4db8108a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default scoring parameter of classifier = mean accuracy\n",
    "model.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fbe70d-4dc8-4e37-b40b-f60ef9a6b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring parameter set to None by default\n",
    "cross_val_score(model, X, y, scoring = None)  # if scoring is not here then model is set to default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0a59ab-e191-41f5-afef-a0cb114fd36c",
   "metadata": {},
   "source": [
    "### Classification model evaluation metrics\n",
    "\n",
    "1. Accuracy\n",
    "2. Area under ROC curver\n",
    "3. Confusion Matrix\n",
    "4. Classification report\n",
    " \n",
    "  **Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b38b9ed-6d24-43ca-9a32-3b0703b17eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "X = heart_disease.drop(\"target\", axis = 1)\n",
    "y = heart_disease[\"target\"]\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "cross_val_score=cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd3f5c-a459-4c60-a6e2-34c4683e750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9ff6f-e972-40a9-8291-ca59df3cce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Heart Disease Classifier Cross-Validated Accuracy: {np.mean(cross_val_score) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0729f0c-5c5c-4387-bdac-bb30ce2a335e",
   "metadata": {},
   "source": [
    "**Area Under Curve (AUC) / ROC**\n",
    "\n",
    "ROC Curves are a comparison of a model's true positive rate (tpr) versus a models false positive rate (fpr)\n",
    "\n",
    "* True positive = model predicts 1 when truth is 1 (target =1 )\n",
    "* False positive = model predicts 1 when truth is 0 (target = 0)\n",
    "* True negative = model predicts 0 when truth is 0\n",
    "* False negative = model predicts 0 when truth is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f5327c-c2d9-4259-b9c1-939d9a698a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13551eba-ba35-49ee-8eeb-987ff0baa35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Fit the classifier\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with probabilities\n",
    "y_probs = model.predict_proba(X_test)\n",
    "\n",
    "y_probs[:10], len(y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf60170-8a50-4d6d-9f57-e224b085b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_positive = y_probs[:,1]\n",
    "y_probs_positive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50579468-a618-44d4-b965-7c2bbf1205bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fpr, tpr, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs_positive)\n",
    "\n",
    "# Check the false positive rates\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec31d2b8-ea55-4943-8988-65bd3d7ce7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for plotting ROC curve\n",
    "import matplotlib.pyplot as fuck\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plots a ROC curve given the false positive rate (fpr) \n",
    "    and true positive rate (tpr) of a model.\n",
    "    \"\"\"\n",
    "    # Plot the ROC curve\n",
    "    fuck.plot (fpr, tpr, color= \"orange\", label= \"ROC\")\n",
    "    # Plot line with no prediction power (baseline)\n",
    "    fuck.plot([0, 1], [0, 1], color= \"darkblue\", linestyle=\"--\", label = \"Guessing\")\n",
    "\n",
    "    # Customize the plot\n",
    "    fuck.xlabel(\"False positive rate (fpr)\")\n",
    "    fuck.ylabel(\"True positive rate (tpr)\")\n",
    "    fuck.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    fuck.legend()\n",
    "    fuck.show()\n",
    "\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b489df-0038-4150-b3e6-bca9c6be6066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_probs_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03093701-47bc-4ffe-b597-18523bee657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot perfect ROC curve and AUC score\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c3c2f-2cf9-4bd5-9be0-972f82091c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfect AUC score\n",
    "roc_auc_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26cb724-8bfb-4c4f-a762-007b8084b376",
   "metadata": {},
   "source": [
    "**Confusion Matirx**\n",
    "\n",
    "  A confusion matrix is a quick way to compare the labels a model predicts and the actual it was supposed to predict.\n",
    "  \n",
    "  In essence, giving you an idea of where the model is getting confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa23cee-2cb6-4f46-a11f-b48bf082c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431c1305-61da-4618-87c2-e5ba9d550ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix with pd.crosstab\n",
    "pd.crosstab(y_test, y_preds, rownames = [\"Actual Labels\"], colnames = [\"Predicted Labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bbb72-845c-45a5-9c61-15da873b7797",
   "metadata": {},
   "outputs": [],
   "source": [
    "22+7+8+24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bd56a7-0e6a-42a9-b375-0e3e06636bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d33e0-7fee-40b6-81f3-41fedeee6771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make our confusion matrix more visual with Seaborn's heatmap()\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the front scale\n",
    "sns.set(font_scale = 1.5)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "# Plot it using Seaborn\n",
    "sns.heatmap(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2a0d2e-b1ec-4f26-a100-59a01d1765ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=model, X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dc0498-75e3-413b-9ded-bd93e4dc7c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_true=y_test, y_pred = y_preds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ecacf-2f7c-4854-b339-62b057d7e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01562f4-654f-4b97-afa6-44a1b12f13a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where precision and recall become valuable\n",
    "disease_true = np.zeros(10000)\n",
    "disease_true[0] = 1 # model predicts every case as 0\n",
    "\n",
    "disease_preds = np.zeros(10000) # model predicts every case as 0\n",
    "\n",
    "pd.DataFrame(classification_report(disease_true, disease_preds, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b70c5f-bbb4-4dca-a054-5713de2165e9",
   "metadata": {},
   "source": [
    "### Regression model evaluation matrix\n",
    "\n",
    "Model Evaluation metrics -  https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "The ones we're going to cover are :\n",
    "1. R^2  or  coefficient of determination\n",
    "2. Mean absolute error (MAE)\n",
    "3. Mean squared error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d31d39d-476b-40e6-9ca3-d74170190925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "housing_df = pd.DataFrame(housing[\"data\"], columns=housing[\"feature_names\"])\n",
    "housing_df[\"target\"] = housing[\"target\"]\n",
    "# housing_df = housing_df.drop(\"MedHouseVal\", axis = 1)\n",
    "housing_df\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop(\"target\", axis = 1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 100)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b5ecb-9731-4b0b-b285-f7cec39ef965",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b347d69e-c234-40df-a7a8-aa5b509f6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Fill the array with y_test mean\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd930bc9-f60f-48e3-ab24-0e5210c59757",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863e679-f0a8-4edd-a75c-ebc70a77d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=y_test, y_pred = y_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675061ae-d619-44c9-9514-060b4817437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=y_test, y_pred = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f299d104-ed35-4ad2-beff-f33cae9ad9d2",
   "metadata": {},
   "source": [
    "**Mean Absolute Error (MAE)**\n",
    "\n",
    "MAE is the average of the absolute differences between predictions and actual values.\n",
    "\n",
    "It gives you an idea of how wrong your models predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a075a8-7c84-48df-b0a2-6c55a67b3d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_preds)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60bac40-1b61-4021-89e3-6fb62a21ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7c3f9f-d8ef-436e-aa22-f93f4f802cb4",
   "metadata": {},
   "source": [
    "### Finally using the scoring Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57078c5e-367e-4560-b310-e06682b0df37",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease = pd.read_csv(\"heart-disease.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37f377-ed63-4723-bb4d-0b33fa616745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis =1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d028a29d-7e62-4561-9580-661cfbecccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Cross-validation score\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring=None)\n",
    "# if scoring = Noen estimators default scoring evaluation metric us used which is accuracy for classification models\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb6842-e535-4b22-af13-816d60034958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validated accuracy\n",
    "print(f\"The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a0dc3-b884-4f99-b6e9-35a390d5888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCURACY\n",
    "np.random.seed(42)\n",
    "# Cross-validation score\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring=\"accuracy\")\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ab824-a256-4f28-911b-8e4550768641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validated accuracy\n",
    "print(f\"The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2fc161-5b6d-4d2e-b91b-4d1cf685da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRECISION\n",
    "np.random.seed(42)\n",
    "# Cross-validation score\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring=\"precision\")\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a644364e-bdb7-49fb-87dd-1d4ccd4b53bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validated accuracy\n",
    "print(f\"The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b854ac49-d986-46e0-a49b-001f7b06c39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECALL\n",
    "np.random.seed(42)\n",
    "cv_recall = cross_val_score(clf, X, y, cv=5, scoring=\"recall\")\n",
    "cv_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee897ed9-a4a7-439e-aa3d-0d8f9cddbfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validated accuracy\n",
    "print(f\"The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193f0723-84ea-4538-8c18-cca0eca98263",
   "metadata": {},
   "source": [
    "Let's see the `scoring` parameter for regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c46552-2dc3-48cf-9fa2-829f6088f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop(\"target\", axis =1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da3c74e-caac-428f-b70d-41e5c47db0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cv_r2 = cross_val_score(model, X, y, cv=3, scoring=None)\n",
    "np.mean(cv_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c408c7-a16a-4da3-89b3-c9e29b8643b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f514a60d-9c6f-4b27-a582-de08f56bf7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean squared error\n",
    "cv_mse = cross_val_score(model, X, y, cv=3, scoring = \"neg_mean_squared_error\")\n",
    "np.mean(cv_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e70ec03-f984-4e60-9248-e7a0038c9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error\n",
    "cv_mae = cross_val_score(model, X, y, cv=3, scoring = \"absolute_error\")\n",
    "np.mean(cv_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801c50f-e089-48b3-90f7-03bee7ee394d",
   "metadata": {},
   "source": [
    "## Using different evaluaation metrics as Scikit-Learn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8749b7-506b-4d58-a756-620325f20bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease = pd.read_csv(\"heart-disease.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459befc8-66f0-4907-9014-371ff0818431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis =1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model using evaluation functions\n",
    "print(\"classifier metrics on the test set\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, model.predict(X_test))*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, model.predict(X_test))*100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, model.predict(X_test))*100:.2f}%\")\n",
    "print(f\"F1: {f1_score(y_test, model.predict(X_test))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1771d8b-51df-4072-ae72-eda4b0efbddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "X = housing_df.drop(\"target\", axis =1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "print(\"Regression metrics on the test set\")\n",
    "print(f\"R2 score: {r2_score(y_test, y_preds)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_preds)}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc0164-2a79-4a05-bff7-f62aab012d80",
   "metadata": {},
   "source": [
    "## Improving a model\n",
    "\n",
    "First predictions = baseline predictions.\n",
    "First model = baseline model.\n",
    "\n",
    "From a data perspective:\n",
    "* Could we collect more data? (generally, the more data more better)\n",
    "* Could we improve our data?\n",
    "\n",
    "  From a model perspective:\n",
    "* Is there a better model we could use?\n",
    "* Could we improve the current model?\n",
    "\n",
    "Parameters = model find patterns in data.\n",
    "Hyperparameters = settings on a model you can adjust to (potentially) improve its liability to find patterns.\n",
    "\n",
    "3 ways to adjust hyperparameters\n",
    "1. By hand\n",
    "2. Randomly with RandomSearchCV\n",
    "3. Exhaustively with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a6e2f-bd5c-4b49-acf5-40ed233242e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5944844-8f68-4abc-abea-1fa6555c9e33",
   "metadata": {},
   "source": [
    "The parameters we are going to adjust\n",
    "\n",
    "* `max_depth`\n",
    "* `max_features`\n",
    "* `min_samples_leaf`\n",
    "* `min_samples_split`\n",
    "* `n_estimators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca13f2-6025-4d0e-be65-58a2dc7a5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Performs evaluation comparison on y_true labels vs y_preds labels\n",
    "    on a classifiacation model.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds)\n",
    "    recall = recall_score(y_true, y_preds)\n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "    metric_dist = {\"accuracy\": round(accuracy, 2), \"precision\": round (precision, 2),\n",
    "                   \"recall\": round(recall, 2),\n",
    "                   \"f1\": round(f1, 2)}\n",
    "    print(f\"Acc:{accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision:{precision * 100:.2f}%\")\n",
    "    print(f\"Recall:{recall * 100:.2f}%\")\n",
    "    print(f\"F1:{f1 * 100:.2f}%\")\n",
    "\n",
    "    return metric_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb5729-dedb-4049-a8b3-4ba1e115d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Shuffle the data\n",
    "heart_disease_shuffled = heart_disease.sample(frac=1)\n",
    "\n",
    "# Split into X and y\n",
    "X = heart_disease_shuffled.drop(\"target\", axis =1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split the data into train, varidation & test sets\n",
    "train_split = round(0.7* len(heart_disease_shuffled))  # 70% of data\n",
    "valid_split = round(train_split + 0.15 * len(heart_disease_shuffled)) # 15 % of data\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_valid, y_valid = X[train_split:valid_split], y[train_split:valid_split]\n",
    "X_test, y_test = X[valid_split:], y[valid_split:]\n",
    "\n",
    "# len(X_train), len(X_valid), len(X_test)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make baseline predictions\n",
    "y_preds = clf.predict(X_valid)\n",
    "\n",
    "# Evaluate the classifier on validation set\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae09872-9b2c-4968-9b6b-cc0d6a687f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Create a second classifier with different hyperparameters\n",
    "clf_2 = RandomForestClassifier(n_estimators=100)\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions \n",
    "y_preds_2 = clf_2.predict(X_valid)\n",
    "\n",
    "# Evaluate the second classifier\n",
    "clf_2_metrics = evaluate_preds(y_valid, y_preds_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf526a1-64b9-4d4d-a5fd-488026d07e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_3 = RandomForestClassifier(n_estimators=100, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6e782c-c554-4aef-96a5-780cad1171c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid = {\"n_estimators\":[10, 100, 200, 500, 1000, 1200],\n",
    "        \"max_depth\": [None, 5, 10, 20, 30],\n",
    "        \"max_features\": [\"auto\", \"sqrt\"],\n",
    "        \"min_samples_split\":[2, 4, 6],\n",
    "        \"min_samples_leaf\":[1, 2, 4]}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into X and y\n",
    "X = heart_disease_shuffled.drop(\"target\", axis = 1)\n",
    "y = heart_disease_shuffled['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=1) # -1 = all processors\n",
    "\n",
    "# setup RandomizedSearchCV\n",
    "rs_clf = RandomizedSearchCV(estimator=clf,\n",
    "                            param_distributions = grid,\n",
    "                            n_iter = 10,\n",
    "                            cv=5,\n",
    "                            verbose=2)\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "rs_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ada44-96f2-4ac0-82a9-2e0724406f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fc66ce-691e-440a-9ce6-05250a848d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the best hyperparameters\n",
    "rs_y_preds = rs_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "rs_metrics = evaluate_preds(y_test, rs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c087f70-ceea-4bf9-bf54-d5b4b7e596ab",
   "metadata": {},
   "source": [
    "## Hyperparametes tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7204c3c-a5d6-4f20-b5d6-a8cbe21d7a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c232a670-9eab-49ef-ac5e-acc68afc441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "3*1*2*1*2*5     # parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b99c5f9-74da-4826-adef-03f63d12e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_2 = {'n_estimators': [100, 200, 500],\n",
    "         'max_depth': [None],\n",
    "         'max_features': ['auto', 'sqrt'],\n",
    "         'min_samples_split': [6],\n",
    "         'min_samples_leaf': [1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eb8262-52f9-4aab-bc97-a92b2a0d9756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into X and y\n",
    "X = heart_disease_shuffled.drop(\"target\", axis = 1)\n",
    "y = heart_disease_shuffled['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=1) # -1 = all processors\n",
    "\n",
    "# setup GridSearchCV\n",
    "gs_clf = GridSearchCV(estimator=clf,\n",
    "                            param_grid = grid_2,\n",
    "                            cv=5,\n",
    "                            verbose=2)\n",
    "# Fit the GridSearchCV version of clf\n",
    "gs_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf50591-5bee-4f40-947c-dfedbef2312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_y_preds = gs_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "gs_metrics = evaluate_preds(y_test, gs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6705e1-e04a-4ff5-95ef-a86f1f1f8818",
   "metadata": {},
   "source": [
    "Let's compare our different models metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33962355-93aa-47c9-9b18-08ce660e63ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_metrics = pd.DataFrame({\"baseline\": baseline_metrics,\n",
    "                               \"clf_2\": clf_2_metrics,\n",
    "                                \"random search\": rs_metrics,\n",
    "                                \"grid search\": gs_metrics})\n",
    "\n",
    "compare_metrics.plot.bar(figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89ef734-077e-4e53-ad6f-83ba663c51a8",
   "metadata": {},
   "source": [
    "## Saving and loading machine learning models\n",
    "\n",
    "Two ways:\n",
    "* With python's Pickle module\n",
    "* With the joblib module/\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a73fef-842e-428c-a150-9eac1732f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save an existing model to file\n",
    "pickle.dump(gs_clf, open(\"gs_random_forest_model_1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf41ba6-8898-4430-90c1-087e72e42b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved model\n",
    "Loaded_pickle_model = pickle.load(open(\"gs_random_random_forest_model_1.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60da7b3-1ca8-4a35-b666-6990e208dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "pickle_y_preds = loaded_pickle_model.predict(X_test)\n",
    "evaluate_preds(y_test, pickle_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cfff75-6aab-4dec-ad3f-427b711987e9",
   "metadata": {},
   "source": [
    "## Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1685e4-b827-4d45-a105-9e3474d541d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save model to file\n",
    "dump(gs_clf, filename=gs_random_forest_model_1.joblib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79fcc68-c613-4098-a053-7aca7bd033f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a saved joblib model\n",
    "loaded_job_model = load(filename = \"gs_random_forest_model_1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f54fbf-010b-459c-8909-9bd602c16e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make and evaluate joblib model\n",
    "joblib_y_preds = loaded_joblib_model.predict(X_test)\n",
    "evaluate_preds(y_test, joblib_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3238fc27-8765-45a5-bed1-378ddbde212f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
